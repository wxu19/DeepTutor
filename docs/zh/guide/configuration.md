# é…ç½®è¯´æ˜

## é…ç½®æ–‡ä»¶

| æ–‡ä»¶ | ç”¨é€” |
|:-----|:--------|
| `.env` | API å¯†é’¥ã€ç«¯å£ã€æœåŠ¡å•† |
| `config/agents.yaml` | LLM å‚æ•°ï¼ˆtemperatureã€max_tokensï¼‰|
| `config/main.yaml` | è·¯å¾„ã€å·¥å…·ã€æ¨¡å—è®¾ç½® |

## ç¯å¢ƒå˜é‡

### å¿…éœ€é…ç½®

```bash
# LLM
LLM_MODEL=gpt-4o
LLM_API_KEY=your_api_key
LLM_HOST=https://api.openai.com/v1

# Embedding
EMBEDDING_MODEL=text-embedding-3-large
EMBEDDING_API_KEY=your_api_key
EMBEDDING_HOST=https://api.openai.com/v1
EMBEDDING_DIMENSION=3072
```

### å¯é€‰é…ç½®

```bash
# æœåŠ¡ç«¯å£ï¼ˆé»˜è®¤ï¼š8001/3782ï¼‰
BACKEND_PORT=8001
FRONTEND_PORT=3782

# è¿œç¨‹è®¿é—®
NEXT_PUBLIC_API_BASE=http://your-server-ip:8001

# ç½‘ç»œæœç´¢
SEARCH_PROVIDER=perplexity  # æˆ–ï¼šbaidu
PERPLEXITY_API_KEY=your_key

# TTS è¯­éŸ³åˆæˆ
TTS_MODEL=
TTS_URL=
TTS_API_KEY=
```

## Agent å‚æ•°

ç¼–è¾‘ `config/agents.yaml`:

```yaml
solve:
  temperature: 0.3
  max_tokens: 8192

research:
  temperature: 0.5
  max_tokens: 12000

question:
  temperature: 0.7
  max_tokens: 4096
```

## æ•°æ®å­˜å‚¨ä½ç½®

```
data/
â”œâ”€â”€ knowledge_bases/    # ä½ ä¸Šä¼ çš„æ–‡æ¡£
â””â”€â”€ user/
    â”œâ”€â”€ solve/          # è§£é¢˜è¾“å‡º
    â”œâ”€â”€ question/       # ç”Ÿæˆçš„é¢˜ç›®
    â”œâ”€â”€ research/       # ç ”ç©¶æŠ¥å‘Š
    â”œâ”€â”€ guide/          # å­¦ä¹ ä¼šè¯
    â””â”€â”€ logs/           # ç³»ç»Ÿæ—¥å¿—
```

---

ğŸ“– **å®Œæ•´å‚è€ƒ**: [config/README.md](https://github.com/HKUDS/DeepTutor/tree/main/config)
